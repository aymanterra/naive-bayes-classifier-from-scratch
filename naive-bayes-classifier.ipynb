{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes Classifier From Scratch \n",
    "## (Gaussian Probabilistic Generative model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Classifier.\n",
    "- Probabilistic Generative model.\n",
    "- Gaussian Assumption for Continuous Inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Generative Models\n",
    "Consider the case of two classes. The posterior probability for class $C_1$ can be written as\n",
    "\n",
    "$$ p(C_1|x) = \\frac{p(x|C_1)p(C_1))}{p(x|C_1)p(C_1) + p(x|C_2)p(C_2)} $$\n",
    "\n",
    "therefore\n",
    "\n",
    "$$ \\therefore p(C_1|x) = \\frac{1}{1 + \\exp(-a)} = \\sigma(a) $$\n",
    "\n",
    "Where\n",
    "\n",
    "$$ a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$$\n",
    "\n",
    "and $ \\sigma(a) $ is the logistic sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Assumption for Continuous Inputs\n",
    "\n",
    "Assuming that the class-conditional densities are Gaussian.\n",
    "\n",
    "$$ p(x|C_k) = \\frac{1}{(2\\pi)^{D/2}} \\frac{1}{|\\Sigma|^{1/2}} \\exp \\{ \\frac{1}{2}(x-\\mu_k)^T \\Sigma^{-1} (x-\\mu_k) \\} $$\n",
    "\n",
    "Consider the case of two classes.\n",
    "\n",
    "$$ p(C_1|x) = \\sigma(\\mathbf{w}^T \\mathbf{x} + w_0) $$\n",
    "\n",
    "where we have defined\n",
    "\n",
    "$$ \\mathbf{w} = \\Sigma^{-1}(\\mu_1 - \\mu_2) $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ w_0 = -\\frac{1}{2} \\mu_1^T \\Sigma^{-1}\\mu_1 + \\frac{1}{2} \\mu_2^T \\Sigma^{-1}\\mu_2 + \\ln{\\frac{p(C_1)}{p(C_2)}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes approximation\n",
    "\n",
    "Sometimes it's difficult to estimate liklihood $p(\\mathbf{x}|C_k)$ for high dimensional data\n",
    "\n",
    "- Naïve Bayes approximation:\n",
    "\n",
    "    $$ p(\\mathbf{x}|C_k) \\approx \\prod_{j=1}^D p(x_j|C_k) $$\n",
    "    \n",
    "- For Gaussian conditional density\n",
    "\n",
    "    $$ p(\\mathbf{x}|C_k) = \\mathscr{N}(x|\\mu,\\Sigma) \\approx \\prod_{j=1}^D p(x_j|C_k) = \\prod_{j=1}^D \\mathscr{N}(x_j|\\mu_j,\\sigma_j^2) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referrence\n",
    "*Pattern Recognition and Machine Learning, Christopher M. Bishop, Springer, 2006*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussian_naive_bayes:\n",
    "    def __mean(self, c):\n",
    "        return np.mean(self.X[self.t == c], axis=0)\n",
    "        \n",
    "    def __variance(self, c):\n",
    "        return np.var(self.X[self.t == c], axis=0)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if (hasattr(self, 'classes_data') & hasattr(self, 'classes') & hasattr(self, 'N')):\n",
    "            g = np.zeros((len(X), len(self.classes)))\n",
    "            i = 0\n",
    "            for c in self.classes:\n",
    "                class_data = self.classes_data[c]\n",
    "                portion = (class_data['n'] / self.N)\n",
    "                exponent = np.exp(-(X-class_data['mean'])**2 / (2* class_data['var']))\n",
    "                denominator = (np.sqrt(2 * np.pi) * np.sqrt(class_data['var']))\n",
    "                g[:, i] = np.prod((1 / denominator) * exponent, axis=1) * portion\n",
    "                i = i + 1\n",
    "            a = np.argmax(g, axis=1)\n",
    "            return a\n",
    "        else:\n",
    "            print('Please run fit in order to be able to use predict')\n",
    "            \n",
    "    def accuracy(self, y_actual, y_predicted):\n",
    "        return np.mean(y_actual == y_predicted) * 100\n",
    "    \n",
    "    def fit(self, X, t):\n",
    "        self.X = X\n",
    "        self.t = t\n",
    "        \n",
    "        self.N = len(t)\n",
    "\n",
    "        self.classes = np.sort(np.unique(t))\n",
    "        \n",
    "        self.classes_data = {}\n",
    "        \n",
    "        for c in self.classes:\n",
    "            self.classes_data[c] = {'mean': self.__mean(c),\n",
    "                                    'var': self.__variance(c),\n",
    "                                    'n': len(self.X[self.t == c])}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.genfromtxt('synth.tr.csv', delimiter=',', skip_header=True)\n",
    "X = Data[:, 1:3]\n",
    "t = Data[:, 3]\n",
    "\n",
    "gnb = gaussian_naive_bayes()\n",
    "gnb.fit(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 89.9 %\n"
     ]
    }
   ],
   "source": [
    "Data_test = np.genfromtxt('synth.te.csv', delimiter=',', skip_header=True)\n",
    "X_test = Data_test[:, 1:3]\n",
    "y_actual = Data_test[:, 3]\n",
    "y_predicted = gnb.predict(X_test)\n",
    "acc = gnb.accuracy(y_actual, y_predicted)\n",
    "print('Accuracy', acc, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data2 = np.genfromtxt('Data1.txt')\n",
    "# Data2 = Data2[Data2[:,0] < 40] # Without outliers\n",
    "X2 = Data2[:, 0:2]\n",
    "t2 = np.array([1 if i >= 0 else 0 for i in Data2[:, 2]])\n",
    "\n",
    "gnb2 = gaussian_naive_bayes()\n",
    "gnb2.fit(X2, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 97.5 %\n"
     ]
    }
   ],
   "source": [
    "Data2_test = np.genfromtxt('Test1.txt')\n",
    "X2_test = Data2_test[:, 0:2]\n",
    "y2_actual = np.array([1 if i >= 0 else 0 for i in Data2_test[:, 2]])\n",
    "y2_predicted = gnb2.predict(X2_test)\n",
    "acc2 = gnb2.accuracy(y2_actual, y2_predicted)\n",
    "print('Accuracy', acc2, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3, t3 = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1, random_state=14, class_sep=1, n_classes=2)\n",
    "\n",
    "gnb3 = gaussian_naive_bayes()\n",
    "gnb3.fit(X3, t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "X3_test, y3_actual = make_classification(n_samples=300, n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1, random_state=14, class_sep=1, n_classes=2)\n",
    "\n",
    "y3_predicted = gnb3.predict(X3_test)\n",
    "acc3 = gnb3.accuracy(y3_predicted, y3_actual)\n",
    "print('Accuracy', acc3, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
